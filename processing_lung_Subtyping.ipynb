{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_quilt1m\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 12 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 12 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 12 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 12 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 12 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rop_quilt1m\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --n_sp 16 --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name rop_quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --n_sp 16 --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold1 --vlm_name rop_quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --n_sp 16 --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold2 --vlm_name rop_quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --n_sp 16 --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold3 --vlm_name rop_quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --n_sp 16 --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold4 --vlm_name rop_quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_</td>\n",
       "      <td>0.8253±0.0442</td>\n",
       "      <td>0.8253±0.0442</td>\n",
       "      <td>0.8250±0.0443</td>\n",
       "      <td>0.8870±0.0355</td>\n",
       "      <td>0.8870±0.0355</td>\n",
       "      <td>0.8253±0.0439</td>\n",
       "      <td>0.8280±0.0427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_</td>\n",
       "      <td>0.9060±0.0238</td>\n",
       "      <td>0.9060±0.0238</td>\n",
       "      <td>0.9057±0.0238</td>\n",
       "      <td>0.9559±0.0134</td>\n",
       "      <td>0.9559±0.0134</td>\n",
       "      <td>0.9056±0.0236</td>\n",
       "      <td>0.9087±0.0248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_ctx:10_oth:2.0_wt:p2c2__flp:4_specific_</td>\n",
       "      <td>0.9088±0.0231</td>\n",
       "      <td>0.9088±0.0231</td>\n",
       "      <td>0.9088±0.0231</td>\n",
       "      <td>0.9633±0.0110</td>\n",
       "      <td>0.9633±0.0110</td>\n",
       "      <td>0.9050±0.0193</td>\n",
       "      <td>0.9069±0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9165±0.0217</td>\n",
       "      <td>0.9165±0.0217</td>\n",
       "      <td>0.9164±0.0217</td>\n",
       "      <td>0.9681±0.0093</td>\n",
       "      <td>0.9681±0.0093</td>\n",
       "      <td>0.9166±0.0214</td>\n",
       "      <td>0.9175±0.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2__flp:4_specific_</td>\n",
       "      <td>0.9098±0.0254</td>\n",
       "      <td>0.9098±0.0254</td>\n",
       "      <td>0.9097±0.0254</td>\n",
       "      <td>0.9659±0.0090</td>\n",
       "      <td>0.9659±0.0090</td>\n",
       "      <td>0.9000±0.0230</td>\n",
       "      <td>0.9018±0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2_flp:2_specific_</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9619±0.0116</td>\n",
       "      <td>0.9619±0.0116</td>\n",
       "      <td>0.9107±0.0101</td>\n",
       "      <td>0.9120±0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2_flp:4_specific_</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9669±0.0120</td>\n",
       "      <td>0.9669±0.0120</td>\n",
       "      <td>0.9088±0.0203</td>\n",
       "      <td>0.9109±0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.7297±0.0372</td>\n",
       "      <td>0.7297±0.0372</td>\n",
       "      <td>0.7197±0.0497</td>\n",
       "      <td>0.8630±0.0464</td>\n",
       "      <td>0.8630±0.0464</td>\n",
       "      <td>0.0000±0.0000</td>\n",
       "      <td>0.0000±0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c_flp:4_specific_</td>\n",
       "      <td>0.9136±0.0152</td>\n",
       "      <td>0.9136±0.0152</td>\n",
       "      <td>0.9136±0.0152</td>\n",
       "      <td>0.9668±0.0098</td>\n",
       "      <td>0.9668±0.0098</td>\n",
       "      <td>0.9108±0.0128</td>\n",
       "      <td>0.9114±0.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:2_specific_</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9605±0.0092</td>\n",
       "      <td>0.9605±0.0092</td>\n",
       "      <td>0.9060±0.0182</td>\n",
       "      <td>0.9069±0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9065±0.0256</td>\n",
       "      <td>0.9065±0.0256</td>\n",
       "      <td>0.9063±0.0258</td>\n",
       "      <td>0.9619±0.0147</td>\n",
       "      <td>0.9619±0.0147</td>\n",
       "      <td>0.9029±0.0311</td>\n",
       "      <td>0.9048±0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c2_flp:2_specific_</td>\n",
       "      <td>0.9050±0.0178</td>\n",
       "      <td>0.9050±0.0178</td>\n",
       "      <td>0.9049±0.0178</td>\n",
       "      <td>0.9621±0.0102</td>\n",
       "      <td>0.9621±0.0102</td>\n",
       "      <td>0.9049±0.0177</td>\n",
       "      <td>0.9064±0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c2_flp:4_specific_</td>\n",
       "      <td>0.9098±0.0262</td>\n",
       "      <td>0.9098±0.0262</td>\n",
       "      <td>0.9097±0.0262</td>\n",
       "      <td>0.9647±0.0114</td>\n",
       "      <td>0.9647±0.0114</td>\n",
       "      <td>0.9089±0.0257</td>\n",
       "      <td>0.9097±0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:10_specific_adapted_</td>\n",
       "      <td>0.9098±0.0251</td>\n",
       "      <td>0.9098±0.0251</td>\n",
       "      <td>0.9097±0.0251</td>\n",
       "      <td>0.9638±0.0172</td>\n",
       "      <td>0.9638±0.0172</td>\n",
       "      <td>0.9094±0.0251</td>\n",
       "      <td>0.9120±0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:12_specific_adapted_</td>\n",
       "      <td>0.8992±0.0136</td>\n",
       "      <td>0.8992±0.0136</td>\n",
       "      <td>0.8991±0.0138</td>\n",
       "      <td>0.9602±0.0109</td>\n",
       "      <td>0.9602±0.0109</td>\n",
       "      <td>0.8982±0.0147</td>\n",
       "      <td>0.9016±0.0123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.8983±0.0162</td>\n",
       "      <td>0.8983±0.0162</td>\n",
       "      <td>0.8982±0.0162</td>\n",
       "      <td>0.9629±0.0077</td>\n",
       "      <td>0.9629±0.0077</td>\n",
       "      <td>0.8984±0.0162</td>\n",
       "      <td>0.9002±0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_adapted_</td>\n",
       "      <td>0.9079±0.0197</td>\n",
       "      <td>0.9079±0.0197</td>\n",
       "      <td>0.9077±0.0198</td>\n",
       "      <td>0.9620±0.0172</td>\n",
       "      <td>0.9620±0.0172</td>\n",
       "      <td>0.9076±0.0198</td>\n",
       "      <td>0.9087±0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_</td>\n",
       "      <td>0.9165±0.0225</td>\n",
       "      <td>0.9165±0.0225</td>\n",
       "      <td>0.9150±0.0133</td>\n",
       "      <td>0.9671±0.0106</td>\n",
       "      <td>0.9671±0.0106</td>\n",
       "      <td>0.9134±0.0210</td>\n",
       "      <td>0.9146±0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_</td>\n",
       "      <td>0.9136±0.0233</td>\n",
       "      <td>0.9136±0.0233</td>\n",
       "      <td>0.9136±0.0233</td>\n",
       "      <td>0.9648±0.0159</td>\n",
       "      <td>0.9648±0.0159</td>\n",
       "      <td>0.9137±0.0234</td>\n",
       "      <td>0.9138±0.0235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_tr:0.5specific_</td>\n",
       "      <td>0.9155±0.0230</td>\n",
       "      <td>0.9155±0.0230</td>\n",
       "      <td>0.9146±0.0143</td>\n",
       "      <td>0.9661±0.0104</td>\n",
       "      <td>0.9661±0.0104</td>\n",
       "      <td>0.9125±0.0213</td>\n",
       "      <td>0.9136±0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:6_specific_adapted_</td>\n",
       "      <td>0.9146±0.0199</td>\n",
       "      <td>0.9146±0.0199</td>\n",
       "      <td>0.9145±0.0199</td>\n",
       "      <td>0.9654±0.0133</td>\n",
       "      <td>0.9654±0.0133</td>\n",
       "      <td>0.9136±0.0216</td>\n",
       "      <td>0.9144±0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:8_specific_adapted_</td>\n",
       "      <td>0.9069±0.0170</td>\n",
       "      <td>0.9069±0.0170</td>\n",
       "      <td>0.9068±0.0169</td>\n",
       "      <td>0.9654±0.0132</td>\n",
       "      <td>0.9654±0.0132</td>\n",
       "      <td>0.9067±0.0166</td>\n",
       "      <td>0.9086±0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_specific_adapted_</td>\n",
       "      <td>0.9098±0.0104</td>\n",
       "      <td>0.9098±0.0104</td>\n",
       "      <td>0.9097±0.0104</td>\n",
       "      <td>0.9567±0.0078</td>\n",
       "      <td>0.9567±0.0078</td>\n",
       "      <td>0.9099±0.0103</td>\n",
       "      <td>0.9107±0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9599±0.0087</td>\n",
       "      <td>0.9599±0.0087</td>\n",
       "      <td>0.9014±0.0075</td>\n",
       "      <td>0.9021±0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:4_specific_</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9036±0.0122</td>\n",
       "      <td>0.9640±0.0100</td>\n",
       "      <td>0.9640±0.0100</td>\n",
       "      <td>0.9076±0.0148</td>\n",
       "      <td>0.9111±0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:wm_flp:4_specific_</td>\n",
       "      <td>0.9136±0.0207</td>\n",
       "      <td>0.9136±0.0207</td>\n",
       "      <td>0.9135±0.0208</td>\n",
       "      <td>0.9640±0.0105</td>\n",
       "      <td>0.9640±0.0105</td>\n",
       "      <td>0.9115±0.0184</td>\n",
       "      <td>0.9129±0.0184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.0001_ctx:16_oth:2.0_wt:p2c_flp:4_sp:16_specif...</td>\n",
       "      <td>0.9261±0.0178</td>\n",
       "      <td>0.9261±0.0178</td>\n",
       "      <td>0.9261±0.0178</td>\n",
       "      <td>0.9727±0.0090</td>\n",
       "      <td>0.9727±0.0090</td>\n",
       "      <td>0.9263±0.0177</td>\n",
       "      <td>0.9270±0.0174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>.0001_ctx:16_oth:2.0_wt:p2c_flp:4_specific_ada...</td>\n",
       "      <td>0.8800±0.0214</td>\n",
       "      <td>0.8800±0.0214</td>\n",
       "      <td>0.8799±0.0214</td>\n",
       "      <td>0.9485±0.0163</td>\n",
       "      <td>0.9485±0.0163</td>\n",
       "      <td>0.8674±0.0168</td>\n",
       "      <td>0.8717±0.0147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             group_id       test_acc  \\\n",
       "0        tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_  0.8253±0.0442   \n",
       "1        tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_  0.9060±0.0238   \n",
       "2           1_ctx:10_oth:2.0_wt:p2c2__flp:4_specific_  0.9088±0.0231   \n",
       "3            1_ctx:12_oth:2.0_wt:mean_flp:4_specific_  0.9165±0.0217   \n",
       "4           1_ctx:12_oth:2.0_wt:p2c2__flp:4_specific_  0.9098±0.0254   \n",
       "5            1_ctx:12_oth:2.0_wt:p2c2_flp:2_specific_  0.9107±0.0100   \n",
       "6            1_ctx:12_oth:2.0_wt:p2c2_flp:4_specific_  0.9088±0.0202   \n",
       "7             1_ctx:12_oth:2.0_wt:p2c_flp:2_specific_  0.7297±0.0372   \n",
       "8             1_ctx:12_oth:2.0_wt:p2c_flp:4_specific_  0.9136±0.0152   \n",
       "9            1_ctx:16_oth:2.0_wt:mean_flp:2_specific_  0.9059±0.0183   \n",
       "10           1_ctx:16_oth:2.0_wt:mean_flp:4_specific_  0.9065±0.0256   \n",
       "11           1_ctx:16_oth:2.0_wt:p2c2_flp:2_specific_  0.9050±0.0178   \n",
       "12           1_ctx:16_oth:2.0_wt:p2c2_flp:4_specific_  0.9098±0.0262   \n",
       "13   1_ctx:16_oth:2.0_wt:p2c_flp:10_specific_adapted_  0.9098±0.0251   \n",
       "14   1_ctx:16_oth:2.0_wt:p2c_flp:12_specific_adapted_  0.8992±0.0136   \n",
       "15            1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_  0.8983±0.0162   \n",
       "16    1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_adapted_  0.9079±0.0197   \n",
       "17            1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_  0.9165±0.0225   \n",
       "18    1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_  0.9136±0.0233   \n",
       "19      1_ctx:16_oth:2.0_wt:p2c_flp:4_tr:0.5specific_  0.9155±0.0230   \n",
       "20    1_ctx:16_oth:2.0_wt:p2c_flp:6_specific_adapted_  0.9146±0.0199   \n",
       "21    1_ctx:16_oth:2.0_wt:p2c_flp:8_specific_adapted_  0.9069±0.0170   \n",
       "22          1_ctx:16_oth:2.0_wt:p2c_specific_adapted_  0.9098±0.0104   \n",
       "23            1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_  0.9040±0.0084   \n",
       "24            1_ctx:16_oth:2.0_wt:p2p_flp:4_specific_  0.9079±0.0150   \n",
       "25             1_ctx:16_oth:2.0_wt:wm_flp:4_specific_  0.9136±0.0207   \n",
       "26  .0001_ctx:16_oth:2.0_wt:p2c_flp:4_sp:16_specif...  0.9261±0.0178   \n",
       "27  .0001_ctx:16_oth:2.0_wt:p2c_flp:4_specific_ada...  0.8800±0.0214   \n",
       "\n",
       "    test_micro_f1  test_macro_f1 test_micro_auc test_macro_auc  \\\n",
       "0   0.8253±0.0442  0.8250±0.0443  0.8870±0.0355  0.8870±0.0355   \n",
       "1   0.9060±0.0238  0.9057±0.0238  0.9559±0.0134  0.9559±0.0134   \n",
       "2   0.9088±0.0231  0.9088±0.0231  0.9633±0.0110  0.9633±0.0110   \n",
       "3   0.9165±0.0217  0.9164±0.0217  0.9681±0.0093  0.9681±0.0093   \n",
       "4   0.9098±0.0254  0.9097±0.0254  0.9659±0.0090  0.9659±0.0090   \n",
       "5   0.9107±0.0100  0.9107±0.0100  0.9619±0.0116  0.9619±0.0116   \n",
       "6   0.9088±0.0202  0.9088±0.0202  0.9669±0.0120  0.9669±0.0120   \n",
       "7   0.7297±0.0372  0.7197±0.0497  0.8630±0.0464  0.8630±0.0464   \n",
       "8   0.9136±0.0152  0.9136±0.0152  0.9668±0.0098  0.9668±0.0098   \n",
       "9   0.9059±0.0183  0.9059±0.0183  0.9605±0.0092  0.9605±0.0092   \n",
       "10  0.9065±0.0256  0.9063±0.0258  0.9619±0.0147  0.9619±0.0147   \n",
       "11  0.9050±0.0178  0.9049±0.0178  0.9621±0.0102  0.9621±0.0102   \n",
       "12  0.9098±0.0262  0.9097±0.0262  0.9647±0.0114  0.9647±0.0114   \n",
       "13  0.9098±0.0251  0.9097±0.0251  0.9638±0.0172  0.9638±0.0172   \n",
       "14  0.8992±0.0136  0.8991±0.0138  0.9602±0.0109  0.9602±0.0109   \n",
       "15  0.8983±0.0162  0.8982±0.0162  0.9629±0.0077  0.9629±0.0077   \n",
       "16  0.9079±0.0197  0.9077±0.0198  0.9620±0.0172  0.9620±0.0172   \n",
       "17  0.9165±0.0225  0.9150±0.0133  0.9671±0.0106  0.9671±0.0106   \n",
       "18  0.9136±0.0233  0.9136±0.0233  0.9648±0.0159  0.9648±0.0159   \n",
       "19  0.9155±0.0230  0.9146±0.0143  0.9661±0.0104  0.9661±0.0104   \n",
       "20  0.9146±0.0199  0.9145±0.0199  0.9654±0.0133  0.9654±0.0133   \n",
       "21  0.9069±0.0170  0.9068±0.0169  0.9654±0.0132  0.9654±0.0132   \n",
       "22  0.9098±0.0104  0.9097±0.0104  0.9567±0.0078  0.9567±0.0078   \n",
       "23  0.9040±0.0084  0.9040±0.0084  0.9599±0.0087  0.9599±0.0087   \n",
       "24  0.9079±0.0150  0.9036±0.0122  0.9640±0.0100  0.9640±0.0100   \n",
       "25  0.9136±0.0207  0.9135±0.0208  0.9640±0.0105  0.9640±0.0105   \n",
       "26  0.9261±0.0178  0.9261±0.0178  0.9727±0.0090  0.9727±0.0090   \n",
       "27  0.8800±0.0214  0.8799±0.0214  0.9485±0.0163  0.9485±0.0163   \n",
       "\n",
       "   test_avg_sensitivity test_avg_specificity  \n",
       "0         0.8253±0.0439        0.8280±0.0427  \n",
       "1         0.9056±0.0236        0.9087±0.0248  \n",
       "2         0.9050±0.0193        0.9069±0.0158  \n",
       "3         0.9166±0.0214        0.9175±0.0214  \n",
       "4         0.9000±0.0230        0.9018±0.0222  \n",
       "5         0.9107±0.0101        0.9120±0.0093  \n",
       "6         0.9088±0.0203        0.9109±0.0201  \n",
       "7         0.0000±0.0000        0.0000±0.0000  \n",
       "8         0.9108±0.0128        0.9114±0.0128  \n",
       "9         0.9060±0.0182        0.9069±0.0183  \n",
       "10        0.9029±0.0311        0.9048±0.0289  \n",
       "11        0.9049±0.0177        0.9064±0.0183  \n",
       "12        0.9089±0.0257        0.9097±0.0260  \n",
       "13        0.9094±0.0251        0.9120±0.0260  \n",
       "14        0.8982±0.0147        0.9016±0.0123  \n",
       "15        0.8984±0.0162        0.9002±0.0156  \n",
       "16        0.9076±0.0198        0.9087±0.0195  \n",
       "17        0.9134±0.0210        0.9146±0.0198  \n",
       "18        0.9137±0.0234        0.9138±0.0235  \n",
       "19        0.9125±0.0213        0.9136±0.0202  \n",
       "20        0.9136±0.0216        0.9144±0.0221  \n",
       "21        0.9067±0.0166        0.9086±0.0175  \n",
       "22        0.9099±0.0103        0.9107±0.0108  \n",
       "23        0.9014±0.0075        0.9021±0.0083  \n",
       "24        0.9076±0.0148        0.9111±0.0140  \n",
       "25        0.9115±0.0184        0.9129±0.0184  \n",
       "26        0.9263±0.0177        0.9270±0.0174  \n",
       "27        0.8674±0.0168        0.8717±0.0147  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "experiment_name = \"lung_subtyping_re\"\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_quilt1m\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 8 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 8 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 8 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 8 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================Parameters========================================\n",
      "n_classes: 2\n",
      "orth_ratio: 2.0\n",
      "weighted_type: p2c\n",
      "n_flp: 4\n",
      "n_sp: 0\n",
      "num_patch_prompt: 26\n",
      "seed: 2023\n",
      "n_ctx: 16\n",
      "experiment_rp: /home/r10user13/TOP/experiment\n",
      "experiment_name: lung_subtyping_re\n",
      "task_type: test\n",
      "learning_rate: 0.0001\n",
      "mask_ratio: 0.0\n",
      "attn_type: \n",
      "is_shared: False\n",
      "only_learn: False\n",
      "num_epochs: 200\n",
      "is_adapted: False\n",
      "tr_ratio: 0\n",
      "proj_name: top\n",
      "vlm_name: quilt1m\n",
      "feature_rp: /data2/r10user13/TOP/lung_quilt1m_20x_448/\n",
      "fold_name: fold0\n",
      "model_fp: /home/r10user13/TOP/experiment/lung_subtyping_re/output/model/quilt1m_fold0_lr:0.0001_ctx:16_oth:2.0_wt:p2c_flp:4_specific__test_best_marco_auc_model.pt\n",
      "early_stop: False\n",
      "clip_base_model: ViT-B/16\n",
      "save_pred_detail: False\n",
      "==========================================================================================\n",
      "test on 209 samples\n",
      "Initializing class-specific contexts\n",
      "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 16\n",
      "Initializing class-specific contexts\n",
      "Initial context: \"X X X X X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 16\n",
      "The pre-trained model is loaded\n",
      "Testing on 209 samples\n",
      "Class 0: acc 0.8113207547169812, correct 86/106\n",
      "Class 1: acc 0.941747572815534, correct 97/103\n",
      "3 26 0.8755980861244019\n"
     ]
    }
   ],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=7 python main.py --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=7 python main.py --model_fp /home/r10user13/TOP/experiment/lung_subtyping_re/output/model/quilt1m_fold0_lr:0.0001_ctx:16_oth:2.0_wt:p2c_flp:4_specific__test_best_marco_auc_model.pt --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:12_oth:2.0_wt:mean_flp:...</td>\n",
       "      <td>0.7129±nan</td>\n",
       "      <td>0.7129±nan</td>\n",
       "      <td>0.7002±nan</td>\n",
       "      <td>0.8587±nan</td>\n",
       "      <td>0.8587±nan</td>\n",
       "      <td>0.6922±nan</td>\n",
       "      <td>0.7371±nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            group_id    test_acc  \\\n",
       "0  quilt1m__lr:0.0001_ctx:12_oth:2.0_wt:mean_flp:...  0.7129±nan   \n",
       "\n",
       "  test_micro_f1 test_macro_f1 test_micro_auc test_macro_auc  \\\n",
       "0    0.7129±nan    0.7002±nan     0.8587±nan     0.8587±nan   \n",
       "\n",
       "  test_avg_sensitivity test_avg_specificity  \n",
       "0           0.6922±nan           0.7371±nan  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "# experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "# experiment_name = \"lung_subtyping\"\n",
    "exp_fp = \"/home/r10user13/TOP/experiment/lung_subtyping_oth\"\n",
    "metric_fp = os.path.join(exp_fp, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:mean_flp:...</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9640±0.0108</td>\n",
       "      <td>0.9640±0.0108</td>\n",
       "      <td>0.9137±0.0208</td>\n",
       "      <td>0.9138±0.0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:mean_flp:...</td>\n",
       "      <td>0.9050±0.0147</td>\n",
       "      <td>0.9050±0.0147</td>\n",
       "      <td>0.9049±0.0148</td>\n",
       "      <td>0.9642±0.0084</td>\n",
       "      <td>0.9642±0.0084</td>\n",
       "      <td>0.9040±0.0147</td>\n",
       "      <td>0.9084±0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_ori__lr:0.0001_ctx:16_oth:1_wt:ori_specific_</td>\n",
       "      <td>0.8455±0.0285</td>\n",
       "      <td>0.8455±0.0285</td>\n",
       "      <td>0.8451±0.0286</td>\n",
       "      <td>0.9099±0.0250</td>\n",
       "      <td>0.9099±0.0250</td>\n",
       "      <td>0.8454±0.0284</td>\n",
       "      <td>0.8487±0.0278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            group_id       test_acc  \\\n",
       "0  quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:mean_flp:...  0.9136±0.0208   \n",
       "1  quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:mean_flp:...  0.9050±0.0147   \n",
       "2   top_ori__lr:0.0001_ctx:16_oth:1_wt:ori_specific_  0.8455±0.0285   \n",
       "\n",
       "   test_micro_f1  test_macro_f1 test_micro_auc test_macro_auc  \\\n",
       "0  0.9136±0.0208  0.9136±0.0208  0.9640±0.0108  0.9640±0.0108   \n",
       "1  0.9050±0.0147  0.9049±0.0148  0.9642±0.0084  0.9642±0.0084   \n",
       "2  0.8455±0.0285  0.8451±0.0286  0.9099±0.0250  0.9099±0.0250   \n",
       "\n",
       "  test_avg_sensitivity test_avg_specificity  \n",
       "0        0.9137±0.0208        0.9138±0.0209  \n",
       "1        0.9040±0.0147        0.9084±0.0116  \n",
       "2        0.8454±0.0284        0.8487±0.0278  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "experiment_name = \"lung_subtyping\"\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:1.0_flp:2_specific_</td>\n",
       "      <td>0.9079±0.0110</td>\n",
       "      <td>0.9079±0.0110</td>\n",
       "      <td>0.9078±0.0111</td>\n",
       "      <td>0.9588±0.0125</td>\n",
       "      <td>0.9588±0.0125</td>\n",
       "      <td>0.9082±0.0114</td>\n",
       "      <td>0.9115±0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_flp:2_specific_</td>\n",
       "      <td>0.9107±0.0143</td>\n",
       "      <td>0.9107±0.0143</td>\n",
       "      <td>0.9106±0.0143</td>\n",
       "      <td>0.9608±0.0117</td>\n",
       "      <td>0.9608±0.0117</td>\n",
       "      <td>0.9105±0.0144</td>\n",
       "      <td>0.9120±0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_specific_</td>\n",
       "      <td>0.9043±nan</td>\n",
       "      <td>0.9043±nan</td>\n",
       "      <td>0.9043±nan</td>\n",
       "      <td>0.9643±nan</td>\n",
       "      <td>0.9643±nan</td>\n",
       "      <td>0.9046±nan</td>\n",
       "      <td>0.9051±nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_weight:sespe...</td>\n",
       "      <td>0.7703±nan</td>\n",
       "      <td>0.7703±nan</td>\n",
       "      <td>0.7702±nan</td>\n",
       "      <td>0.8718±nan</td>\n",
       "      <td>0.8718±nan</td>\n",
       "      <td>0.7702±nan</td>\n",
       "      <td>0.7704±nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_weighted_spe...</td>\n",
       "      <td>0.9139±nan</td>\n",
       "      <td>0.9139±nan</td>\n",
       "      <td>0.9139±nan</td>\n",
       "      <td>0.9592±nan</td>\n",
       "      <td>0.9592±nan</td>\n",
       "      <td>0.9139±nan</td>\n",
       "      <td>0.9139±nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:se_flp:2_...</td>\n",
       "      <td>0.9098±0.0231</td>\n",
       "      <td>0.9098±0.0231</td>\n",
       "      <td>0.9097±0.0231</td>\n",
       "      <td>0.9595±0.0112</td>\n",
       "      <td>0.9595±0.0112</td>\n",
       "      <td>0.9097±0.0231</td>\n",
       "      <td>0.9102±0.0232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:se_specific_</td>\n",
       "      <td>0.9043±nan</td>\n",
       "      <td>0.9043±nan</td>\n",
       "      <td>0.9041±nan</td>\n",
       "      <td>0.9582±nan</td>\n",
       "      <td>0.9582±nan</td>\n",
       "      <td>0.9039±nan</td>\n",
       "      <td>0.9059±nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            group_id       test_acc  \\\n",
       "0  quilt1m__lr:0.0001_ctx:16_oth:1.0_flp:2_specific_  0.9079±0.0110   \n",
       "1  quilt1m__lr:0.0001_ctx:16_oth:2.0_flp:2_specific_  0.9107±0.0143   \n",
       "2        quilt1m__lr:0.0001_ctx:16_oth:2.0_specific_     0.9043±nan   \n",
       "3  quilt1m__lr:0.0001_ctx:16_oth:2.0_weight:sespe...     0.7703±nan   \n",
       "4  quilt1m__lr:0.0001_ctx:16_oth:2.0_weighted_spe...     0.9139±nan   \n",
       "5  quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:se_flp:2_...  0.9098±0.0231   \n",
       "6  quilt1m__lr:0.0001_ctx:16_oth:2.0_wt:se_specific_     0.9043±nan   \n",
       "\n",
       "   test_micro_f1  test_macro_f1 test_micro_auc test_macro_auc  \\\n",
       "0  0.9079±0.0110  0.9078±0.0111  0.9588±0.0125  0.9588±0.0125   \n",
       "1  0.9107±0.0143  0.9106±0.0143  0.9608±0.0117  0.9608±0.0117   \n",
       "2     0.9043±nan     0.9043±nan     0.9643±nan     0.9643±nan   \n",
       "3     0.7703±nan     0.7702±nan     0.8718±nan     0.8718±nan   \n",
       "4     0.9139±nan     0.9139±nan     0.9592±nan     0.9592±nan   \n",
       "5  0.9098±0.0231  0.9097±0.0231  0.9595±0.0112  0.9595±0.0112   \n",
       "6     0.9043±nan     0.9041±nan     0.9582±nan     0.9582±nan   \n",
       "\n",
       "  test_avg_sensitivity test_avg_specificity  \n",
       "0        0.9082±0.0114        0.9115±0.0117  \n",
       "1        0.9105±0.0144        0.9120±0.0152  \n",
       "2           0.9046±nan           0.9051±nan  \n",
       "3           0.7702±nan           0.7704±nan  \n",
       "4           0.9139±nan           0.9139±nan  \n",
       "5        0.9097±0.0231        0.9102±0.0232  \n",
       "6           0.9039±nan           0.9059±nan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment_before\"\n",
    "experiment_name = \"lung_subtyping_ft\"\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup python create_agg_attn_map.py --pl_fp /home/r10user13/TOP/data/lung_vis_process_list_.csv --rp /data2/r10user13/TOP/attention_map/lung_subtyping_re/attn_map/quilt1m --vlm_model quilt1m --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expert-only\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarized prompts\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=5 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --is_adapted --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_</td>\n",
       "      <td>0.8253±0.0442</td>\n",
       "      <td>0.8253±0.0442</td>\n",
       "      <td>0.8250±0.0443</td>\n",
       "      <td>0.8870±0.0355</td>\n",
       "      <td>0.8870±0.0355</td>\n",
       "      <td>0.8253±0.0439</td>\n",
       "      <td>0.8280±0.0427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_</td>\n",
       "      <td>0.9060±0.0238</td>\n",
       "      <td>0.9060±0.0238</td>\n",
       "      <td>0.9057±0.0238</td>\n",
       "      <td>0.9559±0.0134</td>\n",
       "      <td>0.9559±0.0134</td>\n",
       "      <td>0.9056±0.0236</td>\n",
       "      <td>0.9087±0.0248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_ctx:10_oth:2.0_wt:p2c2__flp:4_specific_</td>\n",
       "      <td>0.9088±0.0231</td>\n",
       "      <td>0.9088±0.0231</td>\n",
       "      <td>0.9088±0.0231</td>\n",
       "      <td>0.9633±0.0110</td>\n",
       "      <td>0.9633±0.0110</td>\n",
       "      <td>0.9050±0.0193</td>\n",
       "      <td>0.9069±0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9165±0.0217</td>\n",
       "      <td>0.9165±0.0217</td>\n",
       "      <td>0.9164±0.0217</td>\n",
       "      <td>0.9681±0.0093</td>\n",
       "      <td>0.9681±0.0093</td>\n",
       "      <td>0.9166±0.0214</td>\n",
       "      <td>0.9175±0.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2__flp:4_specific_</td>\n",
       "      <td>0.9098±0.0254</td>\n",
       "      <td>0.9098±0.0254</td>\n",
       "      <td>0.9097±0.0254</td>\n",
       "      <td>0.9659±0.0090</td>\n",
       "      <td>0.9659±0.0090</td>\n",
       "      <td>0.9000±0.0230</td>\n",
       "      <td>0.9018±0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2_flp:2_specific_</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9619±0.0116</td>\n",
       "      <td>0.9619±0.0116</td>\n",
       "      <td>0.9107±0.0101</td>\n",
       "      <td>0.9120±0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2_flp:4_specific_</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9669±0.0120</td>\n",
       "      <td>0.9669±0.0120</td>\n",
       "      <td>0.9088±0.0203</td>\n",
       "      <td>0.9109±0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.7297±0.0372</td>\n",
       "      <td>0.7297±0.0372</td>\n",
       "      <td>0.7197±0.0497</td>\n",
       "      <td>0.8630±0.0464</td>\n",
       "      <td>0.8630±0.0464</td>\n",
       "      <td>0.0000±0.0000</td>\n",
       "      <td>0.0000±0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c_flp:4_specific_</td>\n",
       "      <td>0.9136±0.0152</td>\n",
       "      <td>0.9136±0.0152</td>\n",
       "      <td>0.9136±0.0152</td>\n",
       "      <td>0.9668±0.0098</td>\n",
       "      <td>0.9668±0.0098</td>\n",
       "      <td>0.9108±0.0128</td>\n",
       "      <td>0.9114±0.0128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:2_specific_</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9605±0.0092</td>\n",
       "      <td>0.9605±0.0092</td>\n",
       "      <td>0.9060±0.0182</td>\n",
       "      <td>0.9069±0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9065±0.0256</td>\n",
       "      <td>0.9065±0.0256</td>\n",
       "      <td>0.9063±0.0258</td>\n",
       "      <td>0.9619±0.0147</td>\n",
       "      <td>0.9619±0.0147</td>\n",
       "      <td>0.9029±0.0311</td>\n",
       "      <td>0.9048±0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c2_flp:2_specific_</td>\n",
       "      <td>0.9050±0.0178</td>\n",
       "      <td>0.9050±0.0178</td>\n",
       "      <td>0.9049±0.0178</td>\n",
       "      <td>0.9621±0.0102</td>\n",
       "      <td>0.9621±0.0102</td>\n",
       "      <td>0.9049±0.0177</td>\n",
       "      <td>0.9064±0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c2_flp:4_specific_</td>\n",
       "      <td>0.9098±0.0262</td>\n",
       "      <td>0.9098±0.0262</td>\n",
       "      <td>0.9097±0.0262</td>\n",
       "      <td>0.9647±0.0114</td>\n",
       "      <td>0.9647±0.0114</td>\n",
       "      <td>0.9089±0.0257</td>\n",
       "      <td>0.9097±0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:10_specific_adapted_</td>\n",
       "      <td>0.9077±0.0284</td>\n",
       "      <td>0.9077±0.0284</td>\n",
       "      <td>0.9075±0.0285</td>\n",
       "      <td>0.9638±0.0198</td>\n",
       "      <td>0.9638±0.0198</td>\n",
       "      <td>0.9073±0.0284</td>\n",
       "      <td>0.9103±0.0297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.8983±0.0162</td>\n",
       "      <td>0.8983±0.0162</td>\n",
       "      <td>0.8982±0.0162</td>\n",
       "      <td>0.9629±0.0077</td>\n",
       "      <td>0.9629±0.0077</td>\n",
       "      <td>0.8984±0.0162</td>\n",
       "      <td>0.9002±0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_adapted_</td>\n",
       "      <td>0.9079±0.0197</td>\n",
       "      <td>0.9079±0.0197</td>\n",
       "      <td>0.9077±0.0198</td>\n",
       "      <td>0.9620±0.0172</td>\n",
       "      <td>0.9620±0.0172</td>\n",
       "      <td>0.9076±0.0198</td>\n",
       "      <td>0.9087±0.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_</td>\n",
       "      <td>0.9165±0.0225</td>\n",
       "      <td>0.9165±0.0225</td>\n",
       "      <td>0.9150±0.0133</td>\n",
       "      <td>0.9671±0.0106</td>\n",
       "      <td>0.9671±0.0106</td>\n",
       "      <td>0.9134±0.0210</td>\n",
       "      <td>0.9146±0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_</td>\n",
       "      <td>0.9136±0.0233</td>\n",
       "      <td>0.9136±0.0233</td>\n",
       "      <td>0.9136±0.0233</td>\n",
       "      <td>0.9648±0.0159</td>\n",
       "      <td>0.9648±0.0159</td>\n",
       "      <td>0.9137±0.0234</td>\n",
       "      <td>0.9138±0.0235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_tr:0.5specific_</td>\n",
       "      <td>0.9155±0.0230</td>\n",
       "      <td>0.9155±0.0230</td>\n",
       "      <td>0.9146±0.0143</td>\n",
       "      <td>0.9661±0.0104</td>\n",
       "      <td>0.9661±0.0104</td>\n",
       "      <td>0.9125±0.0213</td>\n",
       "      <td>0.9136±0.0202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:6_specific_adapted_</td>\n",
       "      <td>0.9146±0.0199</td>\n",
       "      <td>0.9146±0.0199</td>\n",
       "      <td>0.9145±0.0199</td>\n",
       "      <td>0.9654±0.0133</td>\n",
       "      <td>0.9654±0.0133</td>\n",
       "      <td>0.9136±0.0216</td>\n",
       "      <td>0.9144±0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:8_specific_adapted_</td>\n",
       "      <td>0.9069±0.0170</td>\n",
       "      <td>0.9069±0.0170</td>\n",
       "      <td>0.9068±0.0169</td>\n",
       "      <td>0.9654±0.0132</td>\n",
       "      <td>0.9654±0.0132</td>\n",
       "      <td>0.9067±0.0166</td>\n",
       "      <td>0.9086±0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_specific_adapted_</td>\n",
       "      <td>0.9098±0.0104</td>\n",
       "      <td>0.9098±0.0104</td>\n",
       "      <td>0.9097±0.0104</td>\n",
       "      <td>0.9567±0.0078</td>\n",
       "      <td>0.9567±0.0078</td>\n",
       "      <td>0.9099±0.0103</td>\n",
       "      <td>0.9107±0.0108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9599±0.0087</td>\n",
       "      <td>0.9599±0.0087</td>\n",
       "      <td>0.9014±0.0075</td>\n",
       "      <td>0.9021±0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:4_specific_</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9036±0.0122</td>\n",
       "      <td>0.9640±0.0100</td>\n",
       "      <td>0.9640±0.0100</td>\n",
       "      <td>0.9076±0.0148</td>\n",
       "      <td>0.9111±0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:wm_flp:4_specific_</td>\n",
       "      <td>0.9136±0.0207</td>\n",
       "      <td>0.9136±0.0207</td>\n",
       "      <td>0.9135±0.0208</td>\n",
       "      <td>0.9640±0.0105</td>\n",
       "      <td>0.9640±0.0105</td>\n",
       "      <td>0.9115±0.0184</td>\n",
       "      <td>0.9129±0.0184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.0001_ctx:16_oth:2.0_wt:p2c_flp:4_sp:16_specif...</td>\n",
       "      <td>0.9261±0.0178</td>\n",
       "      <td>0.9261±0.0178</td>\n",
       "      <td>0.9261±0.0178</td>\n",
       "      <td>0.9727±0.0090</td>\n",
       "      <td>0.9727±0.0090</td>\n",
       "      <td>0.9263±0.0177</td>\n",
       "      <td>0.9270±0.0174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.0001_ctx:16_oth:2.0_wt:p2c_flp:4_specific_ada...</td>\n",
       "      <td>0.8800±0.0214</td>\n",
       "      <td>0.8800±0.0214</td>\n",
       "      <td>0.8799±0.0214</td>\n",
       "      <td>0.9485±0.0163</td>\n",
       "      <td>0.9485±0.0163</td>\n",
       "      <td>0.8674±0.0168</td>\n",
       "      <td>0.8717±0.0147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             group_id       test_acc  \\\n",
       "0        tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_  0.8253±0.0442   \n",
       "1        tx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_  0.9060±0.0238   \n",
       "2           1_ctx:10_oth:2.0_wt:p2c2__flp:4_specific_  0.9088±0.0231   \n",
       "3            1_ctx:12_oth:2.0_wt:mean_flp:4_specific_  0.9165±0.0217   \n",
       "4           1_ctx:12_oth:2.0_wt:p2c2__flp:4_specific_  0.9098±0.0254   \n",
       "5            1_ctx:12_oth:2.0_wt:p2c2_flp:2_specific_  0.9107±0.0100   \n",
       "6            1_ctx:12_oth:2.0_wt:p2c2_flp:4_specific_  0.9088±0.0202   \n",
       "7             1_ctx:12_oth:2.0_wt:p2c_flp:2_specific_  0.7297±0.0372   \n",
       "8             1_ctx:12_oth:2.0_wt:p2c_flp:4_specific_  0.9136±0.0152   \n",
       "9            1_ctx:16_oth:2.0_wt:mean_flp:2_specific_  0.9059±0.0183   \n",
       "10           1_ctx:16_oth:2.0_wt:mean_flp:4_specific_  0.9065±0.0256   \n",
       "11           1_ctx:16_oth:2.0_wt:p2c2_flp:2_specific_  0.9050±0.0178   \n",
       "12           1_ctx:16_oth:2.0_wt:p2c2_flp:4_specific_  0.9098±0.0262   \n",
       "13   1_ctx:16_oth:2.0_wt:p2c_flp:10_specific_adapted_  0.9077±0.0284   \n",
       "14            1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_  0.8983±0.0162   \n",
       "15    1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_adapted_  0.9079±0.0197   \n",
       "16            1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_  0.9165±0.0225   \n",
       "17    1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_adapted_  0.9136±0.0233   \n",
       "18      1_ctx:16_oth:2.0_wt:p2c_flp:4_tr:0.5specific_  0.9155±0.0230   \n",
       "19    1_ctx:16_oth:2.0_wt:p2c_flp:6_specific_adapted_  0.9146±0.0199   \n",
       "20    1_ctx:16_oth:2.0_wt:p2c_flp:8_specific_adapted_  0.9069±0.0170   \n",
       "21          1_ctx:16_oth:2.0_wt:p2c_specific_adapted_  0.9098±0.0104   \n",
       "22            1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_  0.9040±0.0084   \n",
       "23            1_ctx:16_oth:2.0_wt:p2p_flp:4_specific_  0.9079±0.0150   \n",
       "24             1_ctx:16_oth:2.0_wt:wm_flp:4_specific_  0.9136±0.0207   \n",
       "25  .0001_ctx:16_oth:2.0_wt:p2c_flp:4_sp:16_specif...  0.9261±0.0178   \n",
       "26  .0001_ctx:16_oth:2.0_wt:p2c_flp:4_specific_ada...  0.8800±0.0214   \n",
       "\n",
       "    test_micro_f1  test_macro_f1 test_micro_auc test_macro_auc  \\\n",
       "0   0.8253±0.0442  0.8250±0.0443  0.8870±0.0355  0.8870±0.0355   \n",
       "1   0.9060±0.0238  0.9057±0.0238  0.9559±0.0134  0.9559±0.0134   \n",
       "2   0.9088±0.0231  0.9088±0.0231  0.9633±0.0110  0.9633±0.0110   \n",
       "3   0.9165±0.0217  0.9164±0.0217  0.9681±0.0093  0.9681±0.0093   \n",
       "4   0.9098±0.0254  0.9097±0.0254  0.9659±0.0090  0.9659±0.0090   \n",
       "5   0.9107±0.0100  0.9107±0.0100  0.9619±0.0116  0.9619±0.0116   \n",
       "6   0.9088±0.0202  0.9088±0.0202  0.9669±0.0120  0.9669±0.0120   \n",
       "7   0.7297±0.0372  0.7197±0.0497  0.8630±0.0464  0.8630±0.0464   \n",
       "8   0.9136±0.0152  0.9136±0.0152  0.9668±0.0098  0.9668±0.0098   \n",
       "9   0.9059±0.0183  0.9059±0.0183  0.9605±0.0092  0.9605±0.0092   \n",
       "10  0.9065±0.0256  0.9063±0.0258  0.9619±0.0147  0.9619±0.0147   \n",
       "11  0.9050±0.0178  0.9049±0.0178  0.9621±0.0102  0.9621±0.0102   \n",
       "12  0.9098±0.0262  0.9097±0.0262  0.9647±0.0114  0.9647±0.0114   \n",
       "13  0.9077±0.0284  0.9075±0.0285  0.9638±0.0198  0.9638±0.0198   \n",
       "14  0.8983±0.0162  0.8982±0.0162  0.9629±0.0077  0.9629±0.0077   \n",
       "15  0.9079±0.0197  0.9077±0.0198  0.9620±0.0172  0.9620±0.0172   \n",
       "16  0.9165±0.0225  0.9150±0.0133  0.9671±0.0106  0.9671±0.0106   \n",
       "17  0.9136±0.0233  0.9136±0.0233  0.9648±0.0159  0.9648±0.0159   \n",
       "18  0.9155±0.0230  0.9146±0.0143  0.9661±0.0104  0.9661±0.0104   \n",
       "19  0.9146±0.0199  0.9145±0.0199  0.9654±0.0133  0.9654±0.0133   \n",
       "20  0.9069±0.0170  0.9068±0.0169  0.9654±0.0132  0.9654±0.0132   \n",
       "21  0.9098±0.0104  0.9097±0.0104  0.9567±0.0078  0.9567±0.0078   \n",
       "22  0.9040±0.0084  0.9040±0.0084  0.9599±0.0087  0.9599±0.0087   \n",
       "23  0.9079±0.0150  0.9036±0.0122  0.9640±0.0100  0.9640±0.0100   \n",
       "24  0.9136±0.0207  0.9135±0.0208  0.9640±0.0105  0.9640±0.0105   \n",
       "25  0.9261±0.0178  0.9261±0.0178  0.9727±0.0090  0.9727±0.0090   \n",
       "26  0.8800±0.0214  0.8799±0.0214  0.9485±0.0163  0.9485±0.0163   \n",
       "\n",
       "   test_avg_sensitivity test_avg_specificity  \n",
       "0         0.8253±0.0439        0.8280±0.0427  \n",
       "1         0.9056±0.0236        0.9087±0.0248  \n",
       "2         0.9050±0.0193        0.9069±0.0158  \n",
       "3         0.9166±0.0214        0.9175±0.0214  \n",
       "4         0.9000±0.0230        0.9018±0.0222  \n",
       "5         0.9107±0.0101        0.9120±0.0093  \n",
       "6         0.9088±0.0203        0.9109±0.0201  \n",
       "7         0.0000±0.0000        0.0000±0.0000  \n",
       "8         0.9108±0.0128        0.9114±0.0128  \n",
       "9         0.9060±0.0182        0.9069±0.0183  \n",
       "10        0.9029±0.0311        0.9048±0.0289  \n",
       "11        0.9049±0.0177        0.9064±0.0183  \n",
       "12        0.9089±0.0257        0.9097±0.0260  \n",
       "13        0.9073±0.0284        0.9103±0.0297  \n",
       "14        0.8984±0.0162        0.9002±0.0156  \n",
       "15        0.9076±0.0198        0.9087±0.0195  \n",
       "16        0.9134±0.0210        0.9146±0.0198  \n",
       "17        0.9137±0.0234        0.9138±0.0235  \n",
       "18        0.9125±0.0213        0.9136±0.0202  \n",
       "19        0.9136±0.0216        0.9144±0.0221  \n",
       "20        0.9067±0.0166        0.9086±0.0175  \n",
       "21        0.9099±0.0103        0.9107±0.0108  \n",
       "22        0.9014±0.0075        0.9021±0.0083  \n",
       "23        0.9076±0.0148        0.9111±0.0140  \n",
       "24        0.9115±0.0184        0.9129±0.0184  \n",
       "25        0.9263±0.0177        0.9270±0.0174  \n",
       "26        0.8674±0.0168        0.8717±0.0147  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "experiment_name = \"lung_subtyping_re\"\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarized prompts\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=5 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 26, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.bmm(torch.ones(2,26,52).float(), torch.ones(2, 52, 512).float()).shape)\n",
    "\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# b = torch.ones((4,512)).float()\n",
    "# a = torch.tensor(\n",
    "#     [\n",
    "#         [1,2,3,4,5,6],\n",
    "#         [2,4,6,8,10,12],\n",
    "#         [3,6,9,12,15,18],\n",
    "#         [4,8,12,16,20,24]\n",
    "#     ]\n",
    "# ).float()\n",
    "# print(a.shape)\n",
    "\n",
    "# a_1 = F.softmax(a, dim=-1)\n",
    "# re = a.t()@b\n",
    "# print(re/re.norm(dim=1, keepdim=True))\n",
    "\n",
    "# print(\"=======\")\n",
    "# a_2 = F.softmax(a.reshape(2, 2, 6), dim=-1).reshape(4,6)\n",
    "# re = a_2.t()@b\n",
    "# print(re/re.norm(dim=1, keepdim=True))\n",
    "\n",
    "# # re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================Parameters========================================\n",
      "n_classes: 2\n",
      "orth_ratio: 2.0\n",
      "weighted_type: mean\n",
      "n_flp: 4\n",
      "n_sp: 0\n",
      "num_patch_prompt: 26\n",
      "seed: 2023\n",
      "n_ctx: 12\n",
      "experiment_rp: /home/r10user13/TOP/experiment\n",
      "experiment_name: lung_subtyping_oth\n",
      "task_type: train\n",
      "learning_rate: 0.0001\n",
      "mask_ratio: 0.0\n",
      "attn_type: \n",
      "is_shared: False\n",
      "only_learn: False\n",
      "num_epochs: 2\n",
      "proj_name: top\n",
      "vlm_name: quilt1m\n",
      "feature_rp: /data2/r10user13/TOP/graph_data/lung_quilt1m_20x_448/\n",
      "fold_name: fold0\n",
      "model_fp: \n",
      "early_stop: False\n",
      "clip_base_model: ViT-B/16\n",
      "save_pred_detail: False\n",
      "==========================================================================================\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgzypro\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/r10user13/TOP/wandb/run-20231110_012503-s9jjzqwz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mquilt1m_fold0_lr:0.0001_ctx:12_oth:2.0_wt:mean_flp:4_specific_\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/gzypro/lung_subtyping_oth\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/gzypro/lung_subtyping_oth/runs/s9jjzqwz\u001b[0m\n",
      "train on 833 samples, val on 209 samples, test on 209 samples\n",
      "Initializing class-specific contexts\n",
      "Initial context: \"X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 12\n",
      "Initializing class-specific contexts\n",
      "Initial context: \"X X X X X X X X X X X X\"\n",
      "Number of context words (tokens): 12\n",
      "Training on 833 samples\n",
      "Validating on 209 samples\n",
      "Testing on 209 samples\n",
      "\n",
      "\n",
      "prediction: [0 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 1 1 1 0\n",
      " 1 1 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0\n",
      " 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1\n",
      " 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0\n",
      " 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Epoch: 0, train_loss: 12.0972, train_acc: 0.7263\n",
      "Class 0: acc 0.7216981132075472, 306/424\n",
      "Class 1: acc 0.7310513447432763, 299/409\n",
      "prediction: [1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "\n",
      "Val Set, val_loss: 6.0076, val_acc: 0.6890\n",
      "Class 0: acc 0.4716981132075472, 50/106\n",
      "Class 1: acc 0.912621359223301, 94/103\n",
      "Validation loss decreased (inf --> 6.007568).  Saving model ...\n",
      "prediction: [1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1\n",
      " 0 0 0 0 1 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "Class 0: acc 0.4716981132075472, correct 50/106\n",
      "Class 1: acc 0.912621359223301, correct 94/103\n",
      "\n",
      "\n",
      "prediction: [1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0\n",
      " 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 1 1 0 1 0\n",
      " 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 0\n",
      " 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 1\n",
      " 0 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0\n",
      " 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 0 0 1\n",
      " 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1 1 0 0\n",
      " 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1\n",
      " 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1\n",
      " 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 1 1]\n",
      "\n",
      "Epoch: 1, train_loss: 11.5880, train_acc: 0.7863\n",
      "Class 0: acc 0.7641509433962265, 324/424\n",
      "Class 1: acc 0.8092909535452323, 331/409\n",
      "prediction: [1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "\n",
      "Val Set, val_loss: 5.8869, val_acc: 0.7129\n",
      "Class 0: acc 0.5, 53/106\n",
      "Class 1: acc 0.9320388349514563, 96/103\n",
      "Validation loss decreased (6.007568 --> 5.886851).  Saving model ...\n",
      "prediction: [1 1 0 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1\n",
      " 0 0 0 0 0 1 0 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1]\n",
      "Class 0: acc 0.5, correct 53/106\n",
      "Class 1: acc 0.9320388349514563, correct 96/103\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              test_acc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_avg_sensitivity ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_avg_specificity ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             test_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_macro_auc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         test_macro_f1 ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_micro_auc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         test_micro_f1 ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             train_acc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_avg_sensitivity ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_avg_specificity ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_macro_auc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_macro_f1 ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_micro_auc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_micro_f1 ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               val_acc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_avg_sensitivity ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_avg_specificity ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              val_loss █▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_macro_auc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          val_macro_f1 ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_micro_auc ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          val_micro_f1 ▁█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              test_acc 0.71292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_avg_sensitivity 0.71602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  test_avg_specificity 0.76381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             test_loss 5.88685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_macro_auc 0.85867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         test_macro_f1 0.70023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        test_micro_auc 0.85867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         test_micro_f1 0.71292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:             train_acc 0.78631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_avg_sensitivity 0.78672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_avg_specificity 0.78698\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss 11.58799\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_macro_auc 0.85809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_macro_f1 0.7863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_micro_auc 0.85809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_micro_f1 0.78631\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:               val_acc 0.71292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_avg_sensitivity 0.71602\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_avg_specificity 0.76381\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              val_loss 5.88685\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_macro_auc 0.85867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          val_macro_f1 0.70023\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_micro_auc 0.85867\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          val_micro_f1 0.71292\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mquilt1m_fold0_lr:0.0001_ctx:12_oth:2.0_wt:mean_flp:4_specific_\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/gzypro/lung_subtyping_oth/runs/s9jjzqwz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/gzypro/lung_subtyping_oth/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNDI3NjMyOA==/version_details/v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231110_012503-s9jjzqwz/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# graph test\n",
    "CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 python main_graph.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/graph_data/lung_quilt1m_20x_448/ --num_epochs 2 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarized prompts\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2_ --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2_ --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=5 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2_ --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2_ --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=7 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2_ --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarized prompts\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2 --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold0.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2 --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold1.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2 --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold2.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2 --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold3.log 2>&1\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type p2c2 --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_re > /home/r10user13/TOP/log/lung_subtyping_re_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_ctx:10_oth:2.0_wt:p2c2__flp:4_specific_</td>\n",
       "      <td>0.9002±0.0262</td>\n",
       "      <td>0.9002±0.0262</td>\n",
       "      <td>0.9002±0.0262</td>\n",
       "      <td>0.9588±0.0112</td>\n",
       "      <td>0.9588±0.0112</td>\n",
       "      <td>0.8955±0.0212</td>\n",
       "      <td>0.8963±0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9165±0.0217</td>\n",
       "      <td>0.9165±0.0217</td>\n",
       "      <td>0.9164±0.0217</td>\n",
       "      <td>0.9681±0.0093</td>\n",
       "      <td>0.9681±0.0093</td>\n",
       "      <td>0.9166±0.0214</td>\n",
       "      <td>0.9175±0.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2_flp:2_specific_</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9619±0.0116</td>\n",
       "      <td>0.9619±0.0116</td>\n",
       "      <td>0.9107±0.0101</td>\n",
       "      <td>0.9120±0.0093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c2_flp:4_specific_</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9088±0.0202</td>\n",
       "      <td>0.9669±0.0120</td>\n",
       "      <td>0.9669±0.0120</td>\n",
       "      <td>0.9088±0.0203</td>\n",
       "      <td>0.9109±0.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_ctx:12_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.7297±0.0372</td>\n",
       "      <td>0.7297±0.0372</td>\n",
       "      <td>0.7197±0.0497</td>\n",
       "      <td>0.8630±0.0464</td>\n",
       "      <td>0.8630±0.0464</td>\n",
       "      <td>0.0000±0.0000</td>\n",
       "      <td>0.0000±0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:2_specific_</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9059±0.0183</td>\n",
       "      <td>0.9605±0.0092</td>\n",
       "      <td>0.9605±0.0092</td>\n",
       "      <td>0.9060±0.0182</td>\n",
       "      <td>0.9069±0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9065±0.0256</td>\n",
       "      <td>0.9065±0.0256</td>\n",
       "      <td>0.9063±0.0258</td>\n",
       "      <td>0.9619±0.0147</td>\n",
       "      <td>0.9619±0.0147</td>\n",
       "      <td>0.9029±0.0311</td>\n",
       "      <td>0.9048±0.0289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c2_flp:2_specific_</td>\n",
       "      <td>0.9050±0.0178</td>\n",
       "      <td>0.9050±0.0178</td>\n",
       "      <td>0.9049±0.0178</td>\n",
       "      <td>0.9621±0.0102</td>\n",
       "      <td>0.9621±0.0102</td>\n",
       "      <td>0.9049±0.0177</td>\n",
       "      <td>0.9064±0.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c2_flp:4_specific_</td>\n",
       "      <td>0.9098±0.0262</td>\n",
       "      <td>0.9098±0.0262</td>\n",
       "      <td>0.9097±0.0262</td>\n",
       "      <td>0.9647±0.0114</td>\n",
       "      <td>0.9647±0.0114</td>\n",
       "      <td>0.9089±0.0257</td>\n",
       "      <td>0.9097±0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.8983±0.0162</td>\n",
       "      <td>0.8983±0.0162</td>\n",
       "      <td>0.8982±0.0162</td>\n",
       "      <td>0.9629±0.0077</td>\n",
       "      <td>0.9629±0.0077</td>\n",
       "      <td>0.8984±0.0162</td>\n",
       "      <td>0.9002±0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_</td>\n",
       "      <td>0.9136±0.0226</td>\n",
       "      <td>0.9136±0.0226</td>\n",
       "      <td>0.9136±0.0226</td>\n",
       "      <td>0.9625±0.0090</td>\n",
       "      <td>0.9625±0.0090</td>\n",
       "      <td>0.9137±0.0225</td>\n",
       "      <td>0.9146±0.0228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9040±0.0084</td>\n",
       "      <td>0.9599±0.0087</td>\n",
       "      <td>0.9599±0.0087</td>\n",
       "      <td>0.9014±0.0075</td>\n",
       "      <td>0.9021±0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:4_specific_</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9076±0.0150</td>\n",
       "      <td>0.9640±0.0100</td>\n",
       "      <td>0.9640±0.0100</td>\n",
       "      <td>0.9076±0.0148</td>\n",
       "      <td>0.9111±0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:wm_flp:4_specific_</td>\n",
       "      <td>0.9136±0.0207</td>\n",
       "      <td>0.9136±0.0207</td>\n",
       "      <td>0.9135±0.0208</td>\n",
       "      <td>0.9640±0.0105</td>\n",
       "      <td>0.9640±0.0105</td>\n",
       "      <td>0.9115±0.0184</td>\n",
       "      <td>0.9129±0.0184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     group_id       test_acc  test_micro_f1  \\\n",
       "0   1_ctx:10_oth:2.0_wt:p2c2__flp:4_specific_  0.9002±0.0262  0.9002±0.0262   \n",
       "1    1_ctx:12_oth:2.0_wt:mean_flp:4_specific_  0.9165±0.0217  0.9165±0.0217   \n",
       "2    1_ctx:12_oth:2.0_wt:p2c2_flp:2_specific_  0.9107±0.0100  0.9107±0.0100   \n",
       "3    1_ctx:12_oth:2.0_wt:p2c2_flp:4_specific_  0.9088±0.0202  0.9088±0.0202   \n",
       "4     1_ctx:12_oth:2.0_wt:p2c_flp:2_specific_  0.7297±0.0372  0.7297±0.0372   \n",
       "5    1_ctx:16_oth:2.0_wt:mean_flp:2_specific_  0.9059±0.0183  0.9059±0.0183   \n",
       "6    1_ctx:16_oth:2.0_wt:mean_flp:4_specific_  0.9065±0.0256  0.9065±0.0256   \n",
       "7    1_ctx:16_oth:2.0_wt:p2c2_flp:2_specific_  0.9050±0.0178  0.9050±0.0178   \n",
       "8    1_ctx:16_oth:2.0_wt:p2c2_flp:4_specific_  0.9098±0.0262  0.9098±0.0262   \n",
       "9     1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_  0.8983±0.0162  0.8983±0.0162   \n",
       "10    1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_  0.9136±0.0226  0.9136±0.0226   \n",
       "11    1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_  0.9040±0.0084  0.9040±0.0084   \n",
       "12    1_ctx:16_oth:2.0_wt:p2p_flp:4_specific_  0.9079±0.0150  0.9079±0.0150   \n",
       "13     1_ctx:16_oth:2.0_wt:wm_flp:4_specific_  0.9136±0.0207  0.9136±0.0207   \n",
       "\n",
       "    test_macro_f1 test_micro_auc test_macro_auc test_avg_sensitivity  \\\n",
       "0   0.9002±0.0262  0.9588±0.0112  0.9588±0.0112        0.8955±0.0212   \n",
       "1   0.9164±0.0217  0.9681±0.0093  0.9681±0.0093        0.9166±0.0214   \n",
       "2   0.9107±0.0100  0.9619±0.0116  0.9619±0.0116        0.9107±0.0101   \n",
       "3   0.9088±0.0202  0.9669±0.0120  0.9669±0.0120        0.9088±0.0203   \n",
       "4   0.7197±0.0497  0.8630±0.0464  0.8630±0.0464        0.0000±0.0000   \n",
       "5   0.9059±0.0183  0.9605±0.0092  0.9605±0.0092        0.9060±0.0182   \n",
       "6   0.9063±0.0258  0.9619±0.0147  0.9619±0.0147        0.9029±0.0311   \n",
       "7   0.9049±0.0178  0.9621±0.0102  0.9621±0.0102        0.9049±0.0177   \n",
       "8   0.9097±0.0262  0.9647±0.0114  0.9647±0.0114        0.9089±0.0257   \n",
       "9   0.8982±0.0162  0.9629±0.0077  0.9629±0.0077        0.8984±0.0162   \n",
       "10  0.9136±0.0226  0.9625±0.0090  0.9625±0.0090        0.9137±0.0225   \n",
       "11  0.9040±0.0084  0.9599±0.0087  0.9599±0.0087        0.9014±0.0075   \n",
       "12  0.9076±0.0150  0.9640±0.0100  0.9640±0.0100        0.9076±0.0148   \n",
       "13  0.9135±0.0208  0.9640±0.0105  0.9640±0.0105        0.9115±0.0184   \n",
       "\n",
       "   test_avg_specificity  \n",
       "0         0.8963±0.0201  \n",
       "1         0.9175±0.0214  \n",
       "2         0.9120±0.0093  \n",
       "3         0.9109±0.0201  \n",
       "4         0.0000±0.0000  \n",
       "5         0.9069±0.0183  \n",
       "6         0.9048±0.0289  \n",
       "7         0.9064±0.0183  \n",
       "8         0.9097±0.0260  \n",
       "9         0.9002±0.0156  \n",
       "10        0.9146±0.0228  \n",
       "11        0.9021±0.0083  \n",
       "12        0.9111±0.0140  \n",
       "13        0.9129±0.0184  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "experiment_name = \"lung_subtyping_re\"\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original prompts, flp=2\n",
    "# fold0\n",
    "CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold0.log 2>&1\n",
    "\n",
    "# fold1\n",
    "CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 12 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold1.log 2>&1\n",
    "\n",
    "# fold2\n",
    "CUDA_VISIBLE_DEVICES=1 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold2.log 2>&1\n",
    "\n",
    "# fold3\n",
    "CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold3.log 2>&1\n",
    "\n",
    "# fold4\n",
    "CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold4.log 2>&1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original prompts, flp=4\n",
    "# fold0\n",
    "# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold0.log 2>&1\n",
    "\n",
    "# fold1\n",
    "# CUDA_VISIBLE_DEVICES=2 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold1.log 2>&1\n",
    "\n",
    "# fold2\n",
    "# CUDA_VISIBLE_DEVICES=3 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold2.log 2>&1\n",
    "\n",
    "# fold3\n",
    "# CUDA_VISIBLE_DEVICES=4 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold3.log 2>&1\n",
    "\n",
    "# fold4\n",
    "# CUDA_VISIBLE_DEVICES=0 WANDB_API_KEY=97bba4e584826148f126599fde1cd1cf1b8c31a2 nohup python main.py --weighted_type mean --orth_ratio 2 --n_flp 4 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 150 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping > /home/r10user13/TOP/log/lung_subtyping_fold4.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:2_specific_</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9640±0.0108</td>\n",
       "      <td>0.9640±0.0108</td>\n",
       "      <td>0.9137±0.0208</td>\n",
       "      <td>0.9138±0.0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9050±0.0147</td>\n",
       "      <td>0.9050±0.0147</td>\n",
       "      <td>0.9049±0.0148</td>\n",
       "      <td>0.9642±0.0084</td>\n",
       "      <td>0.9642±0.0084</td>\n",
       "      <td>0.9040±0.0147</td>\n",
       "      <td>0.9084±0.0116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   group_id       test_acc  test_micro_f1  \\\n",
       "0  1_ctx:16_oth:2.0_wt:mean_flp:2_specific_  0.9136±0.0208  0.9136±0.0208   \n",
       "1  1_ctx:16_oth:2.0_wt:mean_flp:4_specific_  0.9050±0.0147  0.9050±0.0147   \n",
       "\n",
       "   test_macro_f1 test_micro_auc test_macro_auc test_avg_sensitivity  \\\n",
       "0  0.9136±0.0208  0.9640±0.0108  0.9640±0.0108        0.9137±0.0208   \n",
       "1  0.9049±0.0148  0.9642±0.0084  0.9642±0.0084        0.9040±0.0147   \n",
       "\n",
       "  test_avg_specificity  \n",
       "0        0.9138±0.0209  \n",
       "1        0.9084±0.0116  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "experiment_name = \"lung_subtyping\"\n",
    "\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_micro_f1</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_micro_auc</th>\n",
       "      <th>test_macro_auc</th>\n",
       "      <th>test_avg_sensitivity</th>\n",
       "      <th>test_avg_specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:2_specific_</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9136±0.0208</td>\n",
       "      <td>0.9640±0.0108</td>\n",
       "      <td>0.9640±0.0108</td>\n",
       "      <td>0.9137±0.0208</td>\n",
       "      <td>0.9138±0.0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:4_specific_</td>\n",
       "      <td>0.9175±0.0134</td>\n",
       "      <td>0.9175±0.0134</td>\n",
       "      <td>0.9174±0.0135</td>\n",
       "      <td>0.9644±0.0083</td>\n",
       "      <td>0.9644±0.0083</td>\n",
       "      <td>0.9174±0.0137</td>\n",
       "      <td>0.9182±0.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:mean_flp:8_specific_</td>\n",
       "      <td>0.9031±0.0148</td>\n",
       "      <td>0.9031±0.0148</td>\n",
       "      <td>0.9030±0.0148</td>\n",
       "      <td>0.9592±0.0118</td>\n",
       "      <td>0.9592±0.0118</td>\n",
       "      <td>0.9030±0.0149</td>\n",
       "      <td>0.9046±0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_</td>\n",
       "      <td>0.9098±0.0178</td>\n",
       "      <td>0.9098±0.0178</td>\n",
       "      <td>0.9097±0.0178</td>\n",
       "      <td>0.9643±0.0083</td>\n",
       "      <td>0.9643±0.0083</td>\n",
       "      <td>0.9097±0.0178</td>\n",
       "      <td>0.9111±0.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_</td>\n",
       "      <td>0.9105±0.0102</td>\n",
       "      <td>0.9105±0.0102</td>\n",
       "      <td>0.9105±0.0102</td>\n",
       "      <td>0.9610±0.0108</td>\n",
       "      <td>0.9610±0.0108</td>\n",
       "      <td>0.9107±0.0100</td>\n",
       "      <td>0.9109±0.0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2c_flp:8_specific_</td>\n",
       "      <td>0.8421±nan</td>\n",
       "      <td>0.8421±nan</td>\n",
       "      <td>0.8409±nan</td>\n",
       "      <td>0.9258±nan</td>\n",
       "      <td>0.9258±nan</td>\n",
       "      <td>0.7987±nan</td>\n",
       "      <td>0.7995±nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9079±0.0150</td>\n",
       "      <td>0.9618±0.0101</td>\n",
       "      <td>0.9618±0.0101</td>\n",
       "      <td>0.9081±0.0150</td>\n",
       "      <td>0.9097±0.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:p2p_flp:8_specific_</td>\n",
       "      <td>0.8182±nan</td>\n",
       "      <td>0.8182±nan</td>\n",
       "      <td>0.8182±nan</td>\n",
       "      <td>0.9068±nan</td>\n",
       "      <td>0.9068±nan</td>\n",
       "      <td>0.8195±nan</td>\n",
       "      <td>0.8298±nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:wm_flp:2_specific_</td>\n",
       "      <td>0.9089±0.0264</td>\n",
       "      <td>0.9089±0.0264</td>\n",
       "      <td>0.9088±0.0263</td>\n",
       "      <td>0.9591±0.0182</td>\n",
       "      <td>0.9591±0.0182</td>\n",
       "      <td>0.9089±0.0260</td>\n",
       "      <td>0.9096±0.0265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1_ctx:16_oth:2.0_wt:wm_flp:8_specific_</td>\n",
       "      <td>0.9126±0.0192</td>\n",
       "      <td>0.9126±0.0192</td>\n",
       "      <td>0.9126±0.0192</td>\n",
       "      <td>0.9633±0.0144</td>\n",
       "      <td>0.9633±0.0144</td>\n",
       "      <td>0.9127±0.0194</td>\n",
       "      <td>0.9130±0.0192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   group_id       test_acc  test_micro_f1  \\\n",
       "0  1_ctx:16_oth:2.0_wt:mean_flp:2_specific_  0.9136±0.0208  0.9136±0.0208   \n",
       "1  1_ctx:16_oth:2.0_wt:mean_flp:4_specific_  0.9175±0.0134  0.9175±0.0134   \n",
       "2  1_ctx:16_oth:2.0_wt:mean_flp:8_specific_  0.9031±0.0148  0.9031±0.0148   \n",
       "3   1_ctx:16_oth:2.0_wt:p2c_flp:2_specific_  0.9098±0.0178  0.9098±0.0178   \n",
       "4   1_ctx:16_oth:2.0_wt:p2c_flp:4_specific_  0.9105±0.0102  0.9105±0.0102   \n",
       "5   1_ctx:16_oth:2.0_wt:p2c_flp:8_specific_     0.8421±nan     0.8421±nan   \n",
       "6   1_ctx:16_oth:2.0_wt:p2p_flp:2_specific_  0.9079±0.0150  0.9079±0.0150   \n",
       "7   1_ctx:16_oth:2.0_wt:p2p_flp:8_specific_     0.8182±nan     0.8182±nan   \n",
       "8    1_ctx:16_oth:2.0_wt:wm_flp:2_specific_  0.9089±0.0264  0.9089±0.0264   \n",
       "9    1_ctx:16_oth:2.0_wt:wm_flp:8_specific_  0.9126±0.0192  0.9126±0.0192   \n",
       "\n",
       "   test_macro_f1 test_micro_auc test_macro_auc test_avg_sensitivity  \\\n",
       "0  0.9136±0.0208  0.9640±0.0108  0.9640±0.0108        0.9137±0.0208   \n",
       "1  0.9174±0.0135  0.9644±0.0083  0.9644±0.0083        0.9174±0.0137   \n",
       "2  0.9030±0.0148  0.9592±0.0118  0.9592±0.0118        0.9030±0.0149   \n",
       "3  0.9097±0.0178  0.9643±0.0083  0.9643±0.0083        0.9097±0.0178   \n",
       "4  0.9105±0.0102  0.9610±0.0108  0.9610±0.0108        0.9107±0.0100   \n",
       "5     0.8409±nan     0.9258±nan     0.9258±nan           0.7987±nan   \n",
       "6  0.9079±0.0150  0.9618±0.0101  0.9618±0.0101        0.9081±0.0150   \n",
       "7     0.8182±nan     0.9068±nan     0.9068±nan           0.8195±nan   \n",
       "8  0.9088±0.0263  0.9591±0.0182  0.9591±0.0182        0.9089±0.0260   \n",
       "9  0.9126±0.0192  0.9633±0.0144  0.9633±0.0144        0.9127±0.0194   \n",
       "\n",
       "  test_avg_specificity  \n",
       "0        0.9138±0.0209  \n",
       "1        0.9182±0.0124  \n",
       "2        0.9046±0.0144  \n",
       "3        0.9111±0.0176  \n",
       "4        0.9109±0.0101  \n",
       "5           0.7995±nan  \n",
       "6        0.9097±0.0153  \n",
       "7           0.8298±nan  \n",
       "8        0.9096±0.0265  \n",
       "9        0.9130±0.0192  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from utils.processing_utils import *\n",
    "\n",
    "experiment_rp = \"/home/r10user13/TOP/experiment_before\"\n",
    "experiment_name = \"lung_subtyping_ft_oth\"\n",
    "\n",
    "\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing:\n",
    "\n",
    "The folder structure of the preprocessing part:\n",
    "```\n",
    "├── data\n",
    "    ├── raw_data\n",
    "        ├── LUAD\n",
    "            ├── csv\n",
    "                ├── bm.csv\n",
    "                └── pl_mag{target_mag}x_patch{base_patch_size}_{target_patch_size}.csv\n",
    "            └── segmented_patch\n",
    "                └── pl_mag{target_mag}x_patch{base_patch_size}_{target_patch_size}\n",
    "                    ├── masks\n",
    "                        └── {slide_i}.jpg\n",
    "                    ├── patches\n",
    "                        └── {slide_i}.h5\n",
    "                    ├── stitches\n",
    "                        └── {slide_i}.jpg\n",
    "                    └── process_list_autogen.csv\n",
    "        └── LUSC\n",
    "            ├── csv\n",
    "                ├── bm.csv\n",
    "                └── pl_mag{target_mag}x_patch{base_patch_size}_{target_patch_size}.csv\n",
    "            └── segmented_patch\n",
    "                └── pl_mag{target_mag}x_patch{base_patch_size}_{target_patch_size}\n",
    "                    ├── masks\n",
    "                        └── {slide_i}.jpg\n",
    "                    ├── patches\n",
    "                        └── {slide_i}.h5\n",
    "                    ├── stitches\n",
    "                        └── {slide_i}.jpg\n",
    "                    └── process_list_autogen.csv\n",
    "    └── datasets\n",
    "        └── LUNG\n",
    "            └── {task_name}_label.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Generate processing list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.processing_utils import *\n",
    "\n",
    "generate_pl_bm(\n",
    "        WSI_dir=\"/data1/r10user3/TCGA-WSI/LUSC/LUSC\", \n",
    "        save_dir=\"/home/r10user13/TOP/data/raw_data/\", \n",
    "        base_patch_size=448, \n",
    "        target_mag=20,\n",
    "        number=\"all\",\n",
    "        WSI_name=\"LUSC\"\n",
    ")\n",
    "\n",
    "generate_pl_bm(\n",
    "        WSI_dir=\"/data1/r10user3/TCGA-WSI/LUAD/LUAD\", \n",
    "        save_dir=\"/home/r10user13/TOP/data/raw_data/\", \n",
    "        base_patch_size=448, \n",
    "        target_mag=20,\n",
    "        number=\"all\",\n",
    "        WSI_name=\"LUAD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Segment pathes and save coords information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "# !python create_patches_fp.py \\\n",
    "#     --source /data1/r10user3/TCGA-WSI/LUSC/LUSC \\\n",
    "#     --save_dir /home/r10user13/TOP/data/raw_data/LUSC/segmented_patch/pl_mag20x_patch448_448 \\\n",
    "#     --patch_size 448 \\\n",
    "#     --step_size 448 \\\n",
    "#     --seg \\\n",
    "#     --patch \\\n",
    "#     --stitch \\\n",
    "#     --process_list /home/r10user13/TOP/data/raw_data/LUSC/csv/pl_mag20x_patch448_448.csv\n",
    "\n",
    "# nohup python create_patches_fp.py --source /data1/r10user3/TCGA-WSI/LUSC/LUSC --save_dir /home/r10user13/TOP/data/raw_data/LUSC/segmented_patch/pl_mag20x_patch448_448 --patch_size 448 --step_size 448 --seg --patch --stitch --process_list /home/r10user13/TOP/data/raw_data/LUSC/csv/pl_mag20x_patch448_448.csv\n",
    "\n",
    "# 1.2\n",
    "# !python create_patches_fp.py \\\n",
    "#     --source /data1/r10user3/TCGA-WSI/LUSC/LUSC \\\n",
    "#     --save_dir /home/r10user13/TOP/data/raw_data/LUSC/segmented_patch/pl_mag20x_patch448_896 \\\n",
    "#     --patch_size 896 \\\n",
    "#     --step_size 896 \\\n",
    "#     --seg \\\n",
    "#     --patch \\\n",
    "#     --stitch \\\n",
    "#     --process_list /home/r10user13/TOP/data/raw_data/LUSC/csv/pl_mag20x_patch448_896.csv\n",
    "\n",
    "# nohup python create_patches_fp.py --source /data1/r10user3/TCGA-WSI/LUSC/LUSC --save_dir /home/r10user13/TOP/data/raw_data/LUSC/segmented_patch/pl_mag20x_patch448_896 --patch_size 896 --step_size 896 --seg --patch --stitch --process_list /home/r10user13/TOP/data/raw_data/LUSC/csv/pl_mag20x_patch448_896.csv\n",
    "\n",
    "# 2.1\n",
    "# !python create_patches_fp.py \\\n",
    "#     --source /data1/r10user3/TCGA-WSI/LUAD/LUAD \\\n",
    "#     --save_dir /home/r10user13/TOP/data/raw_data/LUAD/segmented_patch/pl_mag20x_patch448_448 \\\n",
    "#     --patch_size 448 \\\n",
    "#     --step_size 448 \\\n",
    "#     --seg \\\n",
    "#     --patch \\\n",
    "#     --stitch \\\n",
    "#     --process_list /home/r10user13/TOP/data/raw_data/LUAD/csv/pl_mag20x_patch448_448.csv\n",
    "\n",
    "# nohup python create_patches_fp.py --source /data1/r10user3/TCGA-WSI/LUAD/LUAD --save_dir /home/r10user13/TOP/data/raw_data/LUAD/segmented_patch/pl_mag20x_patch448_448 --patch_size 448 --step_size 448 --seg --patch --stitch --process_list /home/r10user13/TOP/data/raw_data/LUAD/csv/pl_mag20x_patch448_448.csv\n",
    "\n",
    "# 2.2\n",
    "# !python create_patches_fp.py \\\n",
    "#     --source /data1/r10user3/TCGA-WSI/LUAD/LUAD \\\n",
    "#     --save_dir /home/r10user13/TOP/data/raw_data/LUAD/segmented_patch/pl_mag20x_patch448_896 \\\n",
    "#     --patch_size 896 \\\n",
    "#     --step_size 896 \\\n",
    "#     --seg \\\n",
    "#     --patch \\\n",
    "#     --stitch \\\n",
    "#     --process_list /home/r10user13/TOP/data/raw_data/LUAD/csv/pl_mag20x_patch448_896.csv\n",
    "    \n",
    "# nohup python create_patches_fp.py --source /data1/r10user3/TCGA-WSI/LUAD/LUAD --save_dir /home/r10user13/TOP/data/raw_data/LUAD/segmented_patch/pl_mag20x_patch448_896 --patch_size 896 --step_size 896 --seg --patch --stitch --process_list /home/r10user13/TOP/data/raw_data/LUAD/csv/pl_mag20x_patch448_896.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Integrate the dataset (Subtyping Classification):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lusc_clinical_fp = \"/data1/r10user3/WSI/clinical_data/LUSC-clinical.tsv\"\n",
    "luad_clinical_fp = \"/data1/r10user3/WSI/clinical_data/LUAD-clinical.tsv\"\n",
    "\n",
    "from utils.processing_utils import *\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "raw_label_luad = list(pd.read_csv(luad_clinical_fp, sep=\"\\t\")[\"case_submitter_id\"])\n",
    "raw_label_lusc = list(pd.read_csv(lusc_clinical_fp, sep=\"\\t\")[\"case_submitter_id\"])\n",
    "\n",
    "file_list = glob.glob(\"/data1/r10user3/TCGA-WSI/LUSC/LUSC/*\")+glob.glob(\"/data1/r10user3/TCGA-WSI/LUAD/LUAD/*\")\n",
    "label_map = {}\n",
    "for file_i in file_list:\n",
    "    file_name = \"-\".join(file_i.split(\"/\")[-1].split(\"-\")[:3])\n",
    "    if file_name in raw_label_luad:\n",
    "        label_map[file_i] = \"luad\"\n",
    "    elif file_name in raw_label_lusc:\n",
    "        label_map[file_i] = \"lusc\"\n",
    "    \n",
    "from utils.processing_utils import *\n",
    "\n",
    "directory_paths = {\n",
    "    '/home/r10user13/TOP/data/raw_data/LUAD/segmented_patch': \"/data1/r10user3/TCGA-WSI/LUAD/LUAD\",\n",
    "    '/home/r10user13/TOP/data/raw_data/LUSC/segmented_patch': \"/data1/r10user3/TCGA-WSI/LUSC/LUSC\"\n",
    "}\n",
    "dataset_path = \"/home/r10user13/TOP/data/datasets/LUNG\"\n",
    "\n",
    "file_name = \"subtyping_label.csv\"\n",
    "\n",
    "label_map = label_map\n",
    "\n",
    "# print(label_map)\n",
    "# generate_label_file(directory_paths, dataset_path, file_name, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quilt1m\n",
    "CUDA_VISIBLE_DEVICES=1 nohup python create_feature_extraction.py  --vlm_model quilt1m --label_fp /home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv  --batch_size 128 --save_rp /data2/r10user13/TOP --num_workers 128 --base_mag 20 --base_patch_size 448\n",
    "\n",
    "# plip\n",
    "CUDA_VISIBLE_DEVICES=7 nohup python create_feature_extraction.py  --vlm_model plip --label_fp /home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv  --batch_size 128 --save_rp /data2/r10user13/TOP --num_workers 32 --base_mag 20 --base_patch_size 448\n",
    "\n",
    "# # clip\n",
    "CUDA_VISIBLE_DEVICES=0 nohup python create_feature_extraction.py  --vlm_model clip --label_fp /home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv  --batch_size 256 --save_rp /data2/r10user13/TOP --num_workers 64 --base_mag 20 --base_patch_size 448"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Dataset split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import os, shutil, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# shot_num = [1,2,4,8,16,32,64]\n",
    "shot_num = \"full_train\"\n",
    "\n",
    "exp_rp = \"/home/r10user13/TOP/experiment\"\n",
    "exp_name = \"lung_subtyping\"\n",
    "fold_num = 5\n",
    "labe_fp = \"/home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv\"\n",
    "\n",
    "\n",
    "label_df = pd.read_csv(labe_fp)\n",
    "data_fp_label_map = dict(zip(\n",
    "    list(label_df[\"slide_fp\"]), list(label_df[\"label\"])\n",
    "))\n",
    "\n",
    "exp_rp_ = os.path.join(exp_rp, exp_name, 'input/csv/split')\n",
    "if not os.path.exists(exp_rp_):\n",
    "    os.makedirs(exp_rp_)\n",
    "    \n",
    "\n",
    "if shot_num == \"full_train\":\n",
    "    slide_fp = label_df[\"slide_fp\"]\n",
    "    seg_fp = label_df[\"seg_fp\"]\n",
    "    label = label_df[\"label\"]\n",
    "    \n",
    "    X = np.array(slide_fp)\n",
    "    y = np.array(label)\n",
    "    skf = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=42)\n",
    "    i = 0 \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = list(X[train_index]), list(X[test_index])\n",
    "        y_train, y_test = list(y[train_index]), list(y[test_index])\n",
    "        X_val, y_val = X_test, y_test\n",
    "        out = pd.DataFrame({\n",
    "            \"data_path\": X_train+X_test+X_val, \n",
    "            \"label\": y_train+y_test+y_val, \n",
    "            \"type\": [\"train\"]*len(X_train)+[\"test\"]*len(X_test)+[\"val\"]*len(X_val)\n",
    "        })\n",
    "        \n",
    "        out.to_csv(os.path.join(exp_rp_, f\"fold{i}.csv\"))\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "else:\n",
    "    data_label = {}\n",
    "    label_list = label_df[\"label\"].unique()\n",
    "    \n",
    "    for label_i in label_list:\n",
    "        slide_fp = label_df[label_df[\"label\"]==label_i][\"slide_fp\"]\n",
    "        seg_fp = label_df[label_df[\"label\"]==label_i][\"seg_fp\"]\n",
    "        label = label_df[label_df[\"label\"]==label_i][\"label\"]\n",
    "        \n",
    "        train_data, data_label[label_i][\"test_data\"], data_label[label_i][\"train_label\"], data_label[label_i][\"test_label\"] = train_test_split(\n",
    "            slide_fp, label, test_size=0.2, stratify=label, random_state=2023)\n",
    "        \n",
    "        random.shuffle(train_data)\n",
    "        data_label[label_i][\"train_data\"] = train_data\n",
    "    \n",
    "    for shot in shot_num:\n",
    "        for i in range(fold_num):\n",
    "            \n",
    "            cur_i = i*shot\n",
    "            data_path_list = []\n",
    "            label_list = []\n",
    "            type_list = []\n",
    "            \n",
    "            for label_i in label_list:\n",
    "                \n",
    "                train_data_i = data_label[label_i][\"train_data\"][cur_i:cur_i+shot]\n",
    "                \n",
    "                test_data_i = data_label[label_i][\"test_data\"]\n",
    "                \n",
    "                val_data_i = random.sample(list(set(data_label[label_i][\"train_data\"])-set(train_data_i)), len(test_data_i))\n",
    "                \n",
    "                data_path_list_i = train_data_i+test_data_i+val_data_i\n",
    "                label_list_i = [data_fp_label_map[data_path] for data_path in data_path_list_i]\n",
    "                type_list_i = [\"train\"]*2*shot_num+[\"test\"]*len(test_data_i)+[\"val\"]*len(val_data_i)\n",
    "                \n",
    "                data_path_list += data_path_list_i\n",
    "                label_list += label_list_i\n",
    "                type_list += type_list_i\n",
    "                \n",
    "                \n",
    "            out = pd.DataFrame({\n",
    "                \"data_path\": data_path_list, \n",
    "                \"label\": label_list, \n",
    "                \"type\": type_list\n",
    "            })\n",
    "            out.to_csv(os.path.join(exp_rp_, f\"fold{i}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# auc = np.array([0.878560858, 0.89335923, 0.866167222, 0.895402088, 0.907125847])\n",
    "# acc = np.array([0.778846154, 0.822115385, 0.740384615, 0.770334928, 0.80861244])\n",
    "\n",
    "# print(f\"auc no train: {np.mean(auc)} +- {np.std(auc)}\")\n",
    "# print(f\"acc no train: {np.mean(acc)} +- {np.std(acc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=6 python main.py --weighted_type se --orth_ratio 2 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=6 nohup python main.py --weighted_type se --orth_ratio 2 --n_flp 2 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft > /home/r10user13/TOP/log/lung_subtyping_ft_fold0.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold0\n",
    "CUDA_VISIBLE_DEVICES=1 nohup python main.py --weighted_type se --orth_ratio 2 --n_ctx 16 --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft > /home/r10user13/TOP/log/lung_subtyping_ft_fold0.log 2>&1\n",
    "\n",
    "# fold1\n",
    "CUDA_VISIBLE_DEVICES=1 nohup python main.py --weighted_type se --orth_ratio 2 --n_flp 2 --n_ctx 16 --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft > /home/r10user13/TOP/log/lung_subtyping_ft_fold1.log 2>&1\n",
    "\n",
    "# fold2\n",
    "CUDA_VISIBLE_DEVICES=2 nohup python main.py --weighted_type se  --orth_ratio 2 --n_flp 2 --n_ctx 16 --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft > /home/r10user13/TOP/log/lung_subtyping_ft_fold2.log 2>&1\n",
    "\n",
    "# fold3\n",
    "CUDA_VISIBLE_DEVICES=4 nohup python main.py --weighted_type se --orth_ratio 2 --n_flp 2 --n_ctx 16 --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft > /home/r10user13/TOP/log/lung_subtyping_ft_fold3.log 2>&1\n",
    "\n",
    "# fold4\n",
    "CUDA_VISIBLE_DEVICES=5 nohup python main.py --weighted_type se --orth_ratio 2 --n_flp 2 --n_ctx 16 --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 200 --learning_rate 0.0001 --task_type train --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft > /home/r10user13/TOP/log/lung_subtyping_ft_fold4.log 2>&1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing and saving attention scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fold0\n",
    "CUDA_VISIBLE_DEVICES=7 python main.py --n_flp 2 --n_ctx 16 --model_fp /home/r10user13/TOP/experiment/lung_subtyping_ft/output/model/quilt1m_fold0_lr:0.0001_ctx:16_oth:1.0_flp:2_specific__test_best_auc_model.pt --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 50 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft \n",
    "CUDA_VISIBLE_DEVICES=3 python main.py --n_ctx 16 --model_fp /home/r10user13/TOP/experiment/lung_subtyping_ft/output/model/quilt1m_fold0_lr:0.0001_ctx:16_specific__test_best_auc_model.pt --fold_name fold0 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 50 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft \n",
    "\n",
    "# # fold1\n",
    "# !python main.py --n_flp 16 --n_ctx 16 --model_fp /home/r10user13/TOP/experiment/lung_subtyping_ft/output/model/quilt1m_fold1_lr:0.0001_ctx:16_flp:16_specific__test_best_auc_model.pt --fold_name fold1 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 50 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft \n",
    "\n",
    "# # # fold2\n",
    "# !python main.py --n_flp 16 --n_ctx 16 --model_fp /home/r10user13/TOP/experiment/lung_subtyping_ft/output/model/quilt1m_fold2_lr:0.0001_ctx:16_flp:16_specific__test_best_auc_model.pt --fold_name fold2 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 50 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft \n",
    "\n",
    "# # fold3\n",
    "# !python main.py --n_flp 16 --n_ctx 16 --model_fp /home/r10user13/TOP/experiment/lung_subtyping_ft/output/model/quilt1m_fold3_lr:0.0001_ctx:16_flp:16_specific__test_best_auc_model.pt --fold_name fold3 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 50 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft \n",
    "\n",
    "# # # fold4\n",
    "# !python main.py --n_flp 16 --n_ctx 16 --model_fp /home/r10user13/TOP/experiment/lung_subtyping_ft/output/model/quilt1m_fold4_lr:0.0001_ctx:16_flp:16_specific__test_best_auc_model.pt --fold_name fold4 --vlm_name quilt1m --feature_rp /data2/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 50 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Postprocessing:\n",
    "## 4.1 Analyze training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_rp = \"/home/r10user13/TOP/experiment\"\n",
    "experiment_name = \"lung_subtyping_ft\"\n",
    "\n",
    "import os\n",
    "metric_fp = os.path.join(experiment_rp, experiment_name, \"output/metrics/metrics.csv\")\n",
    "\n",
    "from utils.processing_utils import *\n",
    "\n",
    "metrics_analysis(metric_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create heatmap of attention score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quilt1m\n",
    "python create_attn_map.py --n_flp 2 --seg --vlm_model quilt1m --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft --process_list /home/r10user13/TOP/data/subtyping_label_pl.csv --label_fp /home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv --n_classes 2 --n_patch_prompt 26\n",
    "\n",
    "# plip\n",
    "python create_attn_map.py --seg --vlm_model plip --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft --process_list /home/r10user13/TOP/data/subtyping_label_pl.csv --label_fp /home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv --n_classes 2 --n_patch_prompt 26\n",
    "\n",
    "# clip\n",
    "python create_attn_map.py --seg --vlm_model plip --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_subtyping_ft --process_list /home/r10user13/TOP/data/subtyping_label_pl.csv --label_fp /home/r10user13/TOP/data/datasets/LUNG/subtyping_label.csv --n_classes 2 --n_patch_prompt 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 分类错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --model_fp /home/r10user13/TOP/experiment/lung_typing_full_train/output/model/quilt1m_fold0_lr:0.0001__test_best_auc_model.pt --fold_name fold0 --vlm_name quilt1m --feature_rp /data1/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 20 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_typing_full_train \n",
    "!python main.py --model_fp /home/r10user13/TOP/experiment/lung_typing_full_train/output/model/quilt1m_fold1_lr:0.0001__test_best_auc_model.pt --fold_name fold1 --vlm_name quilt1m --feature_rp /data1/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 20 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_typing_full_train\n",
    "!python main.py --model_fp /home/r10user13/TOP/experiment/lung_typing_full_train/output/model/quilt1m_fold2_lr:0.0001__test_best_auc_model.pt --fold_name fold2 --vlm_name quilt1m --feature_rp /data1/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 20 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_typing_full_train \n",
    "!python main.py --model_fp /home/r10user13/TOP/experiment/lung_typing_full_train/output/model/quilt1m_fold3_lr:0.0001__test_best_auc_model.pt --fold_name fold3 --vlm_name quilt1m --feature_rp /data1/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 20 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_typing_full_train \n",
    "!python main.py --model_fp /home/r10user13/TOP/experiment/lung_typing_full_train/output/model/quilt1m_fold4_lr:0.0001__test_best_auc_model.pt --fold_name fold4 --vlm_name quilt1m --feature_rp /data1/r10user13/TOP/lung_quilt1m_20x_448/ --num_epochs 20 --learning_rate 0.0001 --task_type test --n_classes 2 --experiment_rp /home/r10user13/TOP/experiment --experiment_name lung_typing_full_train "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
